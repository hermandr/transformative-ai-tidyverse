---
title: "Replication of Paper"
execute:
  warning: false
---

## Set up libraries
```{r}
library(tidyverse)
library(readr)
library(here)
library(infer)

```

## Load Data

```{r}
ai_events = read_csv(here("dev", "ai_events_processed.csv"))
bond_yields = read_csv(here("dev", "bond_yields_processed.csv"))
```

1. ai_events
```{r}
glimpse(ai_events)
```
2. bond_yields

```{r}
glimpse(bond_yields)
```

## Define functions

### Prepare Event Study Data
```{r}
prep_event_study_data <- function(data, event_date, b_days, s_days) {
    # data = idx, date, value 
    # Get the idx of the date as the dates are not sequential
    event_date_idx = data |> filter(date == event_date) |> pull(idx)
    # Filter datasets in event study window and mark before and after
    data |> 
        filter(between(idx, event_date_idx - b_days, event_date_idx + s_days)) |>
        mutate(period = case_when (
            idx < event_date_idx ~ "before",
            idx > event_date_idx ~ "after",
            idx == event_date_idx ~"event"
        )) |>
        filter(period != "event") |> 
        mutate(event_date=event_date)
}
```

## Estimate Effects For One Event Date

### Prepare `dt` with sequential idx as date
```{r}
dt = bond_yields |> 
    arrange(date) |> 
    rowid_to_column(var="idx")
```

### Processing for one Event Date
```{r}
event_date="2024-05-06"
reps=1000
dt |> 
    pivot_longer(
        cols=!all_of(c("idx","date")), 
        names_to = "data_name") |> 
    group_by(data_name) |> 
    group_nest() |> 
    mutate(
        event_data = map(data, ~ prep_event_study_data(.x, event_date = event_date, 15, 15)),
        d_hat = map(event_data, ~ specify(.x, value ~ period) |>
            calculate(stat = "diff in medians", order = c("before","after"))),
    ) |> 
    unnest(d_hat) |> rename(d_hat = stat) |> 
    mutate(
        null_dist = map(event_data, ~ specify(.x, value ~ period) |> 
            hypothesize(null="independence") |> 
            generate(rep=reps, type="permute") |> 
            calculate(stat="diff in medians", order = c("before","after"))),
        p_value = map2(null_dist, d_hat, ~ get_p_value(.x, obs_stat=.y, direction="both"))
    ) |> 
    unnest(p_value) -> result1

```

### Visualize the results

```{r}
pwalk(
    list(result1$null_dist, result1$d_hat, result1$data_name, result1$p_value),
    function(nd, dh, dn, pv) {
        # Calculate confidence interval from the null distribution
        ci <- get_confidence_interval(nd, level = 0.95)
        
        p <- visualize(nd) +
            shade_confidence_interval(ci) + 
            shade_p_value(obs_stat = dh, "both") +
            labs(title = paste("Event Study:", dn, " p-value:", pv))
        print(p)
    }
)
```

## Process for all event dates
```{r}
library(furrr)

# Set up parallel processing
plan(multisession, workers = availableCores() - 1)

reps <- 1000
ai_events |> 
    select(event_date = date) |> 
    crossing(dt) |> 
    pivot_longer(
        cols = !all_of(c("event_date", "idx", "date")), 
        names_to = "data_name"
    ) |> 
    group_by(event_date, data_name) |> 
    group_nest() |> 
    mutate(
        event_data = map2(data, event_date, ~ prep_event_study_data(.x, event_date = .y, 15, 15)),
        d_hat = future_map(event_data, ~ specify(.x, value ~ period) |>
            calculate(stat = "diff in medians", order = c("before", "after")),
            .options = furrr_options(seed = TRUE))
    ) |> 
    unnest(d_hat) |> 
    rename(d_hat = stat) |> 
    mutate(
        null_dist = future_map(event_data, ~ specify(.x, value ~ period) |> 
            hypothesize(null = "independence") |> 
            generate(rep = reps, type = "permute") |> 
            calculate(stat = "diff in medians", order = c("before", "after")),
            .options = furrr_options(seed = TRUE)),
        p_value = map2(null_dist, d_hat, ~ get_p_value(.x, obs_stat = .y, direction = "both"))
    ) |> 
    unnest(p_value) -> result

# Reset to sequential processing when done
plan(sequential)
```

